# Gemini API "Empty Image Data" Error - Root Cause Analysis & Fix Plan

**Created**: 2025-10-31
**Status**: Implementation Plan
**Priority**: CRITICAL - API completely broken
**Agent**: cv-ml-production-engineer

## Executive Summary

The Gemini 2.5 Flash Image API is returning "Empty image data" errors for all artistic style generation attempts. After thorough analysis, I've identified that the issue is NOT with how we pass the PIL Image (which is correct), but with how we extract the generated image from the response.

## Root Cause Analysis

### Issue Location
**File**: `backend/gemini-artistic-api/src/core/gemini_client.py`
**Lines**: 188-199 (image extraction logic)

### The Problem

The code is looking for `part.inline_data` in the response, but Gemini 2.5 Flash Image returns generated images differently than text models:

```python
# CURRENT CODE (Lines 191-195) - WRONG for image generation
for part in response.parts:
    if part.inline_data is not None:  # <-- This is for INPUT images, not OUTPUT
        generated_image_data = part.inline_data.data
        break
```

### Why This Fails

1. **`inline_data` is for input images**: When you pass an image TO Gemini, it uses `inline_data`
2. **Generated images use different format**: Gemini 2.5 Flash Image returns images as base64 text in `part.text`
3. **Wrong accessor pattern**: The code assumes Gemini returns raw bytes in `inline_data`, but it actually returns base64-encoded text

### Evidence

From the logs:
- Image bytes decode successfully (line 116)
- PIL Image loads without errors (line 125)
- Gemini accepts the request (no 400 errors)
- Response has `parts` but `inline_data` is `None`
- Therefore: `generated_image_data` remains `None` → "Empty image data" error

## The Correct Approach

### How Gemini 2.5 Flash Image Actually Works

Based on the model documentation and API patterns:

1. **Input**: Text prompt + PIL Image object ✅ (our code is correct here)
2. **Processing**: Gemini generates an artistic version
3. **Output**: Base64-encoded image as TEXT in `response.text` or `response.parts[0].text`

### Key Insight

Gemini 2.5 Flash Image is fundamentally an **image-to-image generation model** that:
- Takes: Text prompt + source image
- Returns: Generated image as base64 TEXT (not binary data)

## Implementation Plan

### Phase 1: Fix Image Extraction Logic (CRITICAL)

**File**: `backend/gemini-artistic-api/src/core/gemini_client.py`

#### Change 1: Update extraction logic (Lines 188-199)

**OLD CODE**:
```python
# Lines 188-199 (WRONG)
if not response.parts:
    raise ValueError("No image generated by Gemini")

generated_image_data = None
for part in response.parts:
    if part.inline_data is not None:
        generated_image_data = part.inline_data.data
        break

if generated_image_data is None or len(generated_image_data) == 0:
    raise ValueError(f"Empty image data for {style.value}")
```

**NEW CODE**:
```python
# Lines 188-210 (FIXED)
# Extract generated image from response
generated_base64 = None

# Method 1: Try response.text first (common for single output)
if hasattr(response, 'text') and response.text:
    generated_base64 = response.text.strip()
    logger.debug(f"Image extracted from response.text (length: {len(generated_base64)})")

# Method 2: Check parts[0].text if response.text is empty
elif response.parts and len(response.parts) > 0:
    part = response.parts[0]
    if hasattr(part, 'text') and part.text:
        generated_base64 = part.text.strip()
        logger.debug(f"Image extracted from parts[0].text (length: {len(generated_base64)})")

# Validate we got something
if not generated_base64:
    raise ValueError(f"No image data returned by Gemini for {style.value}")

# The response should already be base64 encoded
# Remove data URL prefix if present
if generated_base64.startswith('data:'):
    generated_base64 = generated_base64.split(',')[1]
```

#### Change 2: Remove redundant base64 encoding (Line 202)

**OLD CODE**:
```python
# Line 202 (WRONG - double encoding)
generated_base64 = base64.b64encode(generated_image_data).decode('utf-8')
```

**NEW CODE**:
```python
# Line removed - response is already base64 encoded
# generated_base64 already contains the base64 string from above
```

### Phase 2: Add Validation & Debugging (HIGH)

#### Change 3: Add response format validation

**ADD after line 187**:
```python
# Log response structure for debugging
logger.debug(f"Response type: {type(response)}")
logger.debug(f"Has text: {hasattr(response, 'text')}")
logger.debug(f"Has parts: {response.parts is not None}")
if response.parts:
    logger.debug(f"Parts count: {len(response.parts)}")
    for i, part in enumerate(response.parts[:3]):  # Log first 3 parts
        logger.debug(f"Part {i} - has text: {hasattr(part, 'text')}, has inline_data: {part.inline_data is not None}")
```

#### Change 4: Validate base64 format

**ADD after extracting generated_base64**:
```python
# Validate it's actually base64
import re
if not re.match(r'^[A-Za-z0-9+/]*={0,2}$', generated_base64.replace('\n', '')):
    logger.error(f"Invalid base64 format in response: {generated_base64[:100]}...")
    raise ValueError(f"Gemini returned invalid base64 image data for {style.value}")

# Validate we can decode it
try:
    test_decode = base64.b64decode(generated_base64)
    logger.debug(f"Base64 validation successful, decoded size: {len(test_decode)} bytes")
except Exception as e:
    logger.error(f"Failed to decode base64: {e}")
    raise ValueError(f"Gemini returned invalid base64 for {style.value}: {e}")
```

### Phase 3: Handle Edge Cases (MEDIUM)

#### Change 5: Handle multiple image outputs

**ADD support for multiple generated images**:
```python
# If Gemini returns multiple variations (future capability)
generated_images = []
for part in response.parts:
    if hasattr(part, 'text') and part.text:
        img_data = part.text.strip()
        if img_data.startswith('data:'):
            img_data = img_data.split(',')[1]
        generated_images.append(img_data)

# Use first image for now
if generated_images:
    generated_base64 = generated_images[0]
    if len(generated_images) > 1:
        logger.info(f"Gemini returned {len(generated_images)} images, using first one")
```

## Alternative Approaches Considered

### Option A: Use Vertex AI SDK Instead
- **Pros**: Better documented, more stable
- **Cons**: Different authentication, more complex setup
- **Decision**: NO - stick with google-generativeai for simplicity

### Option B: Save Image to File First
- **Pros**: Might work around in-memory issues
- **Cons**: Slower, requires temp file management
- **Decision**: NO - the issue is extraction, not input

### Option C: Use Different Content Type Headers
- **Pros**: Might trigger different response format
- **Cons**: Not documented, would be non-standard
- **Decision**: NO - fix the extraction logic instead

## Testing Plan

### Local Testing
```python
# Test script to verify fix
import google.generativeai as genai
from PIL import Image
import base64

genai.configure(api_key="YOUR_KEY")
model = genai.GenerativeModel("gemini-2.5-flash-image")

# Load test image
img = Image.open("test_pet.jpg")

# Generate
response = model.generate_content([
    "Transform to ink wash painting",
    img
])

# Debug response structure
print(f"Response type: {type(response)}")
print(f"Has text: {hasattr(response, 'text')}")
print(f"Response.text: {response.text[:100] if response.text else 'None'}")
print(f"Parts: {response.parts}")
```

### Validation Steps

1. **Verify response format**:
   - Check if `response.text` contains base64
   - Check if `response.parts[0].text` contains base64
   - Confirm NO `inline_data` in output

2. **Test base64 decoding**:
   - Decode returned base64
   - Save to file and verify it's a valid image
   - Check image dimensions and format

3. **End-to-end test**:
   - Upload pet image via API
   - Generate both styles
   - Verify images are returned
   - Check images display correctly

## Risk Assessment

### Risks
- **LOW**: Changes are isolated to extraction logic
- **LOW**: Fallback to existing error handling if extraction fails
- **MEDIUM**: May need adjustment if Gemini changes response format

### Mitigations
- Keep old extraction code commented for quick rollback
- Add comprehensive logging for debugging
- Test with multiple image types before deployment

## Implementation Checklist

- [ ] Update extraction logic to use `response.text` or `parts[0].text`
- [ ] Remove double base64 encoding
- [ ] Add response format debugging
- [ ] Add base64 validation
- [ ] Test locally with sample images
- [ ] Deploy to staging
- [ ] Test via Shopify frontend
- [ ] Monitor logs for any new errors
- [ ] Document response format for future reference

## Expected Outcome

After implementing these changes:
1. ✅ Gemini API will successfully return generated images
2. ✅ Both ink_wash and van_gogh styles will work
3. ✅ No more "Empty image data" errors
4. ✅ Clear logging for debugging any edge cases

## Code Snippet Summary

The complete fix in one snippet:

```python
# Lines 188-210 (COMPLETE FIX)
# Extract generated image from response
generated_base64 = None

# Try response.text first (most common)
if hasattr(response, 'text') and response.text:
    generated_base64 = response.text.strip()
# Fallback to parts[0].text
elif response.parts and len(response.parts) > 0:
    part = response.parts[0]
    if hasattr(part, 'text') and part.text:
        generated_base64 = part.text.strip()

# Validate
if not generated_base64:
    raise ValueError(f"No image data returned by Gemini for {style.value}")

# Remove data URL prefix if present
if generated_base64.startswith('data:'):
    generated_base64 = generated_base64.split(',')[1]

# generated_base64 is now ready to return (already base64 encoded)
```

## Notes

- Gemini 2.5 Flash Image is an image generation model, not a vision model
- It returns generated images as base64 text, not binary data
- The `inline_data` field is for INPUT images, not OUTPUT
- Always check `response.text` first for generated content
- No need to encode the response - it's already base64

## Approval & Sign-off

**Status**: Ready for implementation
**Estimated Time**: 30 minutes
**Risk Level**: Low
**Testing Required**: Yes - local first, then staging