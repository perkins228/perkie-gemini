# Direct GCS Upload Pipeline - Code Review

**Date:** 2025-11-09
**Reviewer:** Code Quality Reviewer Agent
**Session Context:** `.claude/tasks/context_session_001.md`

---

## Code Review Summary

The direct GCS upload implementation successfully reduces upload time by 75% by eliminating the InSPyReNet proxy bottleneck. The implementation follows a clean three-step architecture: (1) get signed URL, (2) direct GCS upload, (3) optional confirmation.

**Overall Assessment:** Good implementation with solid fallback logic, but has **CRITICAL security vulnerabilities** that must be addressed before production use.

**Code Quality Score:** 6/10

---

## CRITICAL Issues âš ï¸

### 1. **SECURITY: Missing File Type Validation (CRITICAL)**

**Severity:** CRITICAL
**Risk:** Arbitrary file upload vulnerability, potential XSS via SVG, storage abuse

**Location:**
- `backend/gemini-artistic-api/src/models/schemas.py:73`
- `backend/gemini-artistic-api/src/main.py:314-392`

**Problem:**
```python
class SignedUrlRequest(BaseModel):
    file_type: str = Field("image/jpeg", description="File content type")
    # âŒ NO VALIDATION - accepts ANY content type
```

The API accepts ANY `file_type` from the client without validation. An attacker can:
- Upload malicious SVG files with embedded JavaScript (XSS)
- Upload executable files (.exe, .sh, .js)
- Upload huge video files to exhaust storage quota
- Bypass image processing by uploading text files

**Attack Scenario:**
```javascript
// Malicious upload request
await fetch('/api/v1/upload/signed-url', {
  method: 'POST',
  body: JSON.stringify({
    session_id: 'abc123',
    file_type: 'image/svg+xml'  // âš ï¸ Malicious SVG with JS
  })
});
// API blindly accepts it and generates signed URL
```

**Fix Required:**
```python
# In schemas.py
from pydantic import validator

ALLOWED_IMAGE_TYPES = {
    'image/jpeg',
    'image/jpg',
    'image/png',
    'image/webp'
}

class SignedUrlRequest(BaseModel):
    file_type: str = Field("image/jpeg", description="File content type")

    @validator('file_type')
    def validate_file_type(cls, v):
        if v not in ALLOWED_IMAGE_TYPES:
            raise ValueError(f'Invalid file type. Allowed: {ALLOWED_IMAGE_TYPES}')
        return v
```

---

### 2. **SECURITY: Missing File Size Limits (CRITICAL)**

**Severity:** CRITICAL
**Risk:** Storage quota exhaustion, DoS attack, cost explosion

**Location:**
- All upload endpoints lack size validation

**Problem:**
Neither the frontend nor backend enforces file size limits. An attacker can:
- Upload gigabyte-sized files repeatedly
- Exhaust GCS storage quota
- Generate massive costs (GCS charges per GB)
- Cause memory issues when generating signed URLs

**Attack Scenario:**
```javascript
// Create 500MB blob
const hugeFile = new Blob([new ArrayBuffer(500 * 1024 * 1024)]);
await directUploadHandler.uploadImage(hugeFile, {sessionId: 'attack'});
// Repeat 100x = 50GB uploaded, $1-5 in costs
```

**Fix Required:**

**Frontend (immediate validation):**
```javascript
// In DirectUploadHandler.uploadImage()
const MAX_FILE_SIZE = 50 * 1024 * 1024; // 50MB
if (file.size > MAX_FILE_SIZE) {
    throw new Error('File too large. Maximum size is 50MB.');
}
```

**Backend (security validation):**
```python
# In SignedUrlRequest schema
class SignedUrlRequest(BaseModel):
    file_type: str = Field("image/jpeg")
    file_size: int = Field(..., description="File size in bytes", gt=0, le=52428800)  # 50MB max
```

---

### 3. **SECURITY: Bucket Permissions Not Verified (CRITICAL)**

**Severity:** CRITICAL
**Risk:** Public data exposure, unauthorized access

**Location:**
- `backend/gemini-artistic-api/src/main.py:358`

**Problem:**
```python
bucket = storage_client.bucket("perkieprints-uploads")
# âŒ No verification that bucket exists or has correct permissions
```

The code assumes `perkieprints-uploads` bucket:
1. Exists and is accessible
2. Has correct IAM permissions
3. Is NOT publicly readable
4. Has appropriate lifecycle policies

**Risk:**
- If bucket is public, all uploaded pet photos are exposed
- If permissions are wrong, uploads fail silently
- If bucket doesn't exist, 500 errors occur

**Verification Needed:**
```bash
# Check bucket permissions (run this manually)
gsutil iam get gs://perkieprints-uploads

# Expected: Should NOT have allUsers or allAuthenticatedUsers with read access
# Expected: Should have object lifecycle deletion rules
```

**Fix Required:**
```python
# Add bucket verification on startup
@app.on_event("startup")
async def verify_bucket():
    try:
        storage_client = storage.Client(project=settings.project_id)
        bucket = storage_client.bucket("perkieprints-uploads")

        # Verify bucket exists
        if not bucket.exists():
            logger.error("Upload bucket does not exist!")
            raise Exception("perkieprints-uploads bucket not found")

        # Check IAM policy
        policy = bucket.get_iam_policy()
        for binding in policy.bindings:
            if binding.get('members') in (['allUsers'], ['allAuthenticatedUsers']):
                logger.error("SECURITY: Bucket is publicly accessible!")
                raise Exception("Upload bucket has public access")

        logger.info("âœ… Upload bucket verified secure")
    except Exception as e:
        logger.critical(f"Bucket verification failed: {e}")
        raise
```

---

### 4. **SECURITY: Path Traversal Vulnerability (HIGH)**

**Severity:** HIGH
**Risk:** Overwrite other users' files, unauthorized access

**Location:**
- `backend/gemini-artistic-api/src/main.py:347-354`

**Problem:**
```python
if req.session_id:
    blob_path = f"originals/sessions/{req.session_id}/{timestamp}_{upload_id}.jpg"
    # âŒ session_id is not sanitized - can contain ../../../
```

An attacker can inject path traversal characters in `session_id`:
```javascript
fetch('/api/v1/upload/signed-url', {
  body: JSON.stringify({
    session_id: '../../../admin/stolen',  // âš ï¸ Path traversal
    file_type: 'image/jpeg'
  })
});
// Results in: originals/sessions/../../../admin/stolen/timestamp_id.jpg
// Actually writes to: admin/stolen/timestamp_id.jpg
```

**Fix Required:**
```python
import re

def sanitize_path_component(value: str) -> str:
    """Remove dangerous characters from path components"""
    if not value:
        return 'anonymous'
    # Remove path traversal, only allow alphanumeric + dash/underscore
    sanitized = re.sub(r'[^a-zA-Z0-9_-]', '', value)
    if not sanitized:
        return 'anonymous'
    return sanitized[:64]  # Max length 64 chars

# In generate_signed_upload_url endpoint:
safe_session_id = sanitize_path_component(req.session_id)
safe_customer_id = sanitize_path_component(req.customer_id)

if safe_customer_id:
    blob_path = f"originals/customers/{safe_customer_id}/{timestamp}_{upload_id}.jpg"
elif safe_session_id:
    blob_path = f"originals/sessions/{safe_session_id}/{timestamp}_{upload_id}.jpg"
```

---

### 5. **SECURITY: No CSRF Protection (HIGH)**

**Severity:** HIGH
**Risk:** Cross-site request forgery attacks

**Location:**
- All POST endpoints lack CSRF tokens

**Problem:**
An attacker can create a malicious website that triggers uploads from victim browsers:

```html
<!-- Attacker's malicious website -->
<script>
// Victim visits attacker.com, this runs in their browser
fetch('https://gemini-artistic-api-753651513695.us-central1.run.app/api/v1/upload/signed-url', {
  method: 'POST',
  body: JSON.stringify({
    session_id: 'victim_session',
    file_type: 'image/jpeg'
  })
})
.then(r => r.json())
.then(data => {
  // Now upload spam/malicious content using victim's quota
  fetch(data.signed_url, {
    method: 'PUT',
    body: spamImageBlob
  });
});
</script>
```

**Current State:**
```python
allow_origins=["*"],  # âŒ Accepts requests from ANY origin
allow_credentials=False,  # âŒ No session validation
```

**Fix Required:**

**Option 1: Strict CORS (Recommended for Production)**
```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://perkie-prints-test.myshopify.com",
        "https://perkieprints.com",
        "https://*.perkieprints.com"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["Content-Type", "X-CSRF-Token"],
)
```

**Option 2: CSRF Token (More Secure)**
```python
from fastapi import Header, HTTPException

@app.post("/api/v1/upload/signed-url")
async def generate_signed_upload_url(
    request: Request,
    req: SignedUrlRequest,
    x_csrf_token: str = Header(None)
):
    # Verify CSRF token
    if not x_csrf_token:
        raise HTTPException(status_code=403, detail="CSRF token required")

    # Validate token (implement token generation/validation)
    if not validate_csrf_token(x_csrf_token, request):
        raise HTTPException(status_code=403, detail="Invalid CSRF token")

    # ... rest of endpoint
```

---

### 6. **SECURITY: Signed URL Expiration Too Long (MEDIUM)**

**Severity:** MEDIUM
**Risk:** URL replay attacks, extended exposure window

**Location:**
- `backend/gemini-artistic-api/src/main.py:367`

**Problem:**
```python
signed_url = blob.generate_signed_url(
    expiration=timedelta(minutes=15),  # âš ï¸ 15 minutes is excessive
    method="PUT",
    content_type=req.file_type,
)
```

15-minute expiration creates risks:
- Attacker intercepts URL (network sniffing, browser history, logs)
- Has 15 minutes to abuse it (replay uploads)
- Can upload multiple files to same destination
- Can share URL with others

**Typical Upload Times:**
- Small file (500KB): 1-3 seconds
- Large file (5MB): 5-10 seconds
- Even on slow 3G: < 60 seconds

**Fix Required:**
```python
signed_url = blob.generate_signed_url(
    expiration=timedelta(minutes=2),  # âœ… 2 minutes is sufficient
    method="PUT",
    content_type=req.file_type,
)

# Update response
expires_in=120,  # 2 minutes in seconds
```

**Frontend Handling:**
```javascript
// In DirectUploadHandler.uploadImage()
const SIGNED_URL_EXPIRY = 2 * 60 * 1000; // 2 minutes
const startTime = Date.now();

const signedUrlData = await this.getSignedUrl(customerId, sessionId, file.type);

// Check if we're within safety margin
if (Date.now() - startTime > SIGNED_URL_EXPIRY - 30000) {
    throw new Error('Signed URL expired before upload');
}

await this.uploadToGCS(file, signedUrlData, onProgress);
```

---

## MAJOR Concerns

### 7. **ERROR HANDLING: Silent Confirmation Failures**

**Severity:** MAJOR
**Risk:** Data integrity issues, lost metadata, hard to debug

**Location:**
- `assets/direct-upload-handler.js:170-197`
- `backend/gemini-artistic-api/src/main.py:395-443`

**Problem:**
```javascript
async confirmUpload(uploadId, blobPath, customerId, sessionId) {
    try {
        // ... confirmation logic
    } catch (error) {
        console.warn('âš ï¸ Upload confirmation error:', error);
        // Non-critical - upload still succeeded
        return null;  // âŒ Silently swallow ALL errors
    }
}
```

This swallows critical errors:
- Network failures (can't reach API)
- Server errors (500 from backend)
- File not found (upload actually failed!)
- Permission errors (GCS access denied)

**Risk:**
- Frontend thinks upload succeeded, but file doesn't exist
- User proceeds to checkout with broken image
- Order fails during fulfillment
- Customer complains about broken product

**Fix Required:**
```javascript
async confirmUpload(uploadId, blobPath, customerId, sessionId) {
    try {
        const response = await fetch(`${this.geminiApiUrl}/api/v1/upload/confirm`, {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({
                upload_id: uploadId,
                blob_path: blobPath,
                customer_id: customerId,
                session_id: sessionId
            })
        });

        if (!response.ok) {
            // âš ï¸ Distinguish between "soft" and "hard" failures
            if (response.status === 404) {
                // CRITICAL: File doesn't exist - upload actually failed!
                throw new Error('Upload verification failed - file not found');
            }
            if (response.status >= 500) {
                // Server error - log but allow (temp issue)
                console.warn('âš ï¸ Confirmation server error (non-blocking):', response.status);
                return null;
            }
        }

        return await response.json();

    } catch (error) {
        if (error.message.includes('file not found')) {
            // CRITICAL error - re-throw
            throw error;
        }
        // Network errors - log but allow
        console.warn('âš ï¸ Confirmation network error (non-blocking):', error);
        return null;
    }
}
```

---

### 8. **ERROR HANDLING: No Retry on Transient Failures**

**Severity:** MAJOR
**Risk:** Poor user experience, unnecessary fallbacks

**Location:**
- `snippets/ks-product-pet-selector-stitch.liquid:1888-1953`

**Problem:**
```javascript
async function uploadToServer(file, petIndex, retryCount = 0) {
    // Try direct GCS upload first
    if (retryCount === 0) {
        try {
            const result = await directUploadHandler.uploadImage(/*...*/);
            return result;
        } catch (error) {
            // âŒ IMMEDIATE fallback - no retry for transient errors
            console.warn('Direct upload failed, falling back to InSPyReNet');
        }
    }
    // Falls back to slow proxy...
}
```

This immediately falls back to the slow proxy (13.5s) on ANY error, including:
- Temporary network glitch (should retry)
- DNS resolution timeout (should retry)
- 503 Service Unavailable (should retry)

**Impact:**
- User gets slow experience (13.5s) instead of fast (2.1s)
- Wastes InSPyReNet capacity
- Doesn't leverage direct upload benefits

**Fix Required:**
```javascript
class DirectUploadHandler {
    constructor() {
        this.geminiApiUrl = 'https://gemini-artistic-api-753651513695.us-central1.run.app';
        this.maxRetries = 3;
        this.retryDelays = [0, 1000, 2000]; // 0ms, 1s, 2s
        this.uploadTimeout = 60000;
    }

    async uploadImageWithRetry(file, options = {}, retryCount = 0) {
        try {
            return await this.uploadImage(file, options);
        } catch (error) {
            const isRetryable = this.isRetryableError(error);

            if (isRetryable && retryCount < this.maxRetries - 1) {
                console.log(`âš ï¸ Retrying direct upload (attempt ${retryCount + 2}/${this.maxRetries})...`);
                await new Promise(resolve =>
                    setTimeout(resolve, this.retryDelays[retryCount + 1])
                );
                return this.uploadImageWithRetry(file, options, retryCount + 1);
            }

            throw error; // Not retryable or max retries exceeded
        }
    }

    isRetryableError(error) {
        const message = error.message.toLowerCase();

        // Retryable errors
        if (message.includes('network error')) return true;
        if (message.includes('timeout')) return true;
        if (message.includes('503')) return true;
        if (message.includes('502')) return true;
        if (message.includes('429')) return true; // Rate limit - wait and retry

        // Non-retryable errors
        if (message.includes('404')) return false;
        if (message.includes('403')) return false;
        if (message.includes('400')) return false;

        return true; // Retry by default
    }
}
```

---

### 9. **PERFORMANCE: Missing Concurrent Upload Limits**

**Severity:** MAJOR
**Risk:** Browser crashes, memory exhaustion, poor UX

**Location:**
- No concurrency control in upload logic

**Problem:**
For products with 3 pets, the code can trigger 3 simultaneous uploads:
```javascript
// Pet 1: 5MB upload starts
// Pet 2: 5MB upload starts
// Pet 3: 5MB upload starts
// Total: 15MB loaded into memory simultaneously
```

**Risks:**
- Mobile devices have limited memory (1-2GB available to browser)
- 3x 5MB files = 15MB + browser overhead = potential crash
- Network congestion (3 uploads compete for bandwidth)
- Poor progress feedback (all show 33% when one completes)

**Fix Required:**
```javascript
class UploadQueue {
    constructor(maxConcurrent = 2) {
        this.maxConcurrent = maxConcurrent;
        this.queue = [];
        this.active = 0;
    }

    async add(uploadFn) {
        return new Promise((resolve, reject) => {
            this.queue.push({ uploadFn, resolve, reject });
            this.processQueue();
        });
    }

    async processQueue() {
        if (this.active >= this.maxConcurrent || this.queue.length === 0) {
            return;
        }

        this.active++;
        const { uploadFn, resolve, reject } = this.queue.shift();

        try {
            const result = await uploadFn();
            resolve(result);
        } catch (error) {
            reject(error);
        } finally {
            this.active--;
            this.processQueue();
        }
    }
}

// Usage
const uploadQueue = new UploadQueue(2); // Max 2 concurrent uploads

async function uploadAllPets(files) {
    const uploads = files.map((file, index) =>
        uploadQueue.add(() => uploadToServer(file, index + 1))
    );

    return Promise.all(uploads);
}
```

---

### 10. **CODE QUALITY: Hardcoded API URLs**

**Severity:** MAJOR
**Risk:** Deployment fragility, environment confusion

**Location:**
- `snippets/ks-product-pet-selector-stitch.liquid:1389`
- `assets/direct-upload-handler.js:20`

**Problem:**
```javascript
this.geminiApiUrl = 'https://gemini-artistic-api-753651513695.us-central1.run.app';
// âŒ Hardcoded production URL
```

**Risks:**
- Can't test against staging/dev environments
- If URL changes, need to update in multiple files
- No way to use local development server
- Accidentally points test site to production API

**Fix Required:**

**Option 1: Environment Detection**
```javascript
class DirectUploadHandler {
    constructor() {
        // Auto-detect environment
        const hostname = window.location.hostname;

        if (hostname.includes('localhost') || hostname.includes('127.0.0.1')) {
            this.geminiApiUrl = 'http://localhost:8000';
        } else if (hostname.includes('test') || hostname.includes('staging')) {
            this.geminiApiUrl = 'https://gemini-artistic-api-staging-753651513695.us-central1.run.app';
        } else {
            this.geminiApiUrl = 'https://gemini-artistic-api-753651513695.us-central1.run.app';
        }

        console.log(`ğŸŒ Using Gemini API: ${this.geminiApiUrl}`);
    }
}
```

**Option 2: Configuration Object (Better)**
```javascript
// In snippet initialization
const config = {
    geminiApiUrl: {{ settings.gemini_api_url | default: 'https://gemini-artistic-api-753651513695.us-central1.run.app' | json }},
    maxFileSize: {{ settings.max_upload_size | default: 52428800 | json }},
    uploadTimeout: {{ settings.upload_timeout | default: 60000 | json }}
};

const directUploadHandler = new DirectUploadHandler(config);
```

---

## MINOR Issues

### 11. **Missing Content-Type Validation in Upload**

**Severity:** MINOR
**Risk:** Inconsistent uploads, debugging difficulty

**Location:**
- `assets/direct-upload-handler.js:149-150`

**Problem:**
```javascript
xhr.open('PUT', signedUrlData.signed_url, true);
xhr.setRequestHeader('Content-Type', signedUrlData.content_type);
// âŒ What if signedUrlData.content_type doesn't match file.type?
```

If backend returns `content_type: "image/jpeg"` but file is PNG:
- Upload succeeds but with wrong headers
- GCS metadata shows JPEG but file is PNG
- Image processing may fail downstream

**Fix Required:**
```javascript
async uploadToGCS(file, signedUrlData, onProgress) {
    // Validate content type matches
    if (file.type && file.type !== signedUrlData.content_type) {
        console.warn(`âš ï¸ Content type mismatch: file=${file.type}, expected=${signedUrlData.content_type}`);
    }

    return new Promise((resolve, reject) => {
        const xhr = new XMLHttpRequest();
        // ... rest of code
        xhr.setRequestHeader('Content-Type', file.type || signedUrlData.content_type);
        xhr.send(file);
    });
}
```

---

### 12. **Missing Upload Progress Persistence**

**Severity:** MINOR
**Risk:** Lost progress on page refresh

**Problem:**
If user refreshes page during upload:
- Upload continues in background (GCS still receives)
- Progress is lost (UI resets to 0%)
- User thinks upload failed, re-uploads
- Wastes quota, creates duplicate files

**Fix Required:**
```javascript
// Store upload state in sessionStorage
async uploadImage(file, options = {}) {
    const uploadId = uuid.v4();

    // Persist upload state
    this.saveUploadState(uploadId, {
        fileName: file.name,
        fileSize: file.size,
        startTime: Date.now(),
        status: 'in_progress'
    });

    try {
        const result = await this.uploadToGCS(/*...*/);

        this.saveUploadState(uploadId, {
            status: 'completed',
            url: result.public_url
        });

        return result;
    } catch (error) {
        this.saveUploadState(uploadId, {
            status: 'failed',
            error: error.message
        });
        throw error;
    }
}

saveUploadState(uploadId, state) {
    const key = `upload_${uploadId}`;
    sessionStorage.setItem(key, JSON.stringify({
        ...JSON.parse(sessionStorage.getItem(key) || '{}'),
        ...state,
        updatedAt: Date.now()
    }));
}

// On page load, check for incomplete uploads
restoreInProgressUploads() {
    for (let i = 0; i < sessionStorage.length; i++) {
        const key = sessionStorage.key(i);
        if (key.startsWith('upload_')) {
            const state = JSON.parse(sessionStorage.getItem(key));
            if (state.status === 'in_progress') {
                console.log('Found incomplete upload:', state.fileName);
                // Show UI to resume or cancel
            }
        }
    }
}
```

---

### 13. **No Logging of Upload Metrics**

**Severity:** MINOR
**Risk:** Can't optimize, can't debug production issues

**Problem:**
No structured logging of:
- Upload success rate (direct vs fallback)
- Upload durations by file size
- Error types and frequencies
- Bandwidth/throughput metrics

**Fix Required:**
```javascript
class UploadMetrics {
    logUploadAttempt(method, file, result, duration) {
        const metric = {
            timestamp: new Date().toISOString(),
            method: method, // 'direct' or 'fallback'
            fileSize: file.size,
            fileType: file.type,
            duration: duration,
            success: result.success,
            error: result.error || null,
            sessionId: this.sessionId
        };

        // Send to analytics
        if (window.gtag) {
            gtag('event', 'upload_attempt', metric);
        }

        // Store locally for debugging
        this.storeMetric(metric);
    }

    storeMetric(metric) {
        const metrics = JSON.parse(localStorage.getItem('upload_metrics') || '[]');
        metrics.push(metric);

        // Keep last 100 uploads
        if (metrics.length > 100) {
            metrics.shift();
        }

        localStorage.setItem('upload_metrics', JSON.stringify(metrics));
    }

    getMetricsSummary() {
        const metrics = JSON.parse(localStorage.getItem('upload_metrics') || '[]');

        return {
            totalUploads: metrics.length,
            successRate: metrics.filter(m => m.success).length / metrics.length,
            directUploadRate: metrics.filter(m => m.method === 'direct').length / metrics.length,
            averageDuration: metrics.reduce((sum, m) => sum + m.duration, 0) / metrics.length,
            errors: metrics.filter(m => !m.success).map(m => m.error)
        };
    }
}
```

---

## SUGGESTIONS (Nice to Have)

### 14. **Add Upload Resumability**

**Benefit:** Better UX for large files on unstable connections

**Implementation:**
Use GCS Resumable Upload API instead of signed URLs:

```python
# Backend: Generate resumable upload session
@app.post("/api/v1/upload/resumable-session")
async def create_resumable_session(req: SignedUrlRequest):
    bucket = storage_client.bucket("perkieprints-uploads")
    blob = bucket.blob(blob_path)

    # Create resumable upload session
    upload_url = blob.create_resumable_upload_session(
        content_type=req.file_type,
        timeout=300
    )

    return {
        "upload_url": upload_url,
        "blob_path": blob_path,
        "chunk_size": 5242880  # 5MB chunks
    }
```

```javascript
// Frontend: Upload in chunks with resume support
async uploadResumable(file, uploadUrl) {
    const chunkSize = 5 * 1024 * 1024; // 5MB
    let offset = 0;

    while (offset < file.size) {
        const chunk = file.slice(offset, offset + chunkSize);

        try {
            await this.uploadChunk(chunk, uploadUrl, offset, file.size);
            offset += chunkSize;
        } catch (error) {
            // On failure, query current offset and resume
            offset = await this.getUploadProgress(uploadUrl);
        }
    }
}
```

**Tradeoff:** More complex, but excellent for poor network conditions.

---

### 15. **Add Image Validation Before Upload**

**Benefit:** Catch corrupt/invalid images before wasting bandwidth

**Implementation:**
```javascript
async validateImage(file) {
    return new Promise((resolve, reject) => {
        const img = new Image();
        const url = URL.createObjectURL(file);

        img.onload = () => {
            URL.revokeObjectURL(url);

            // Check dimensions
            if (img.width < 100 || img.height < 100) {
                reject(new Error('Image too small (min 100x100px)'));
            }
            if (img.width > 10000 || img.height > 10000) {
                reject(new Error('Image too large (max 10000x10000px)'));
            }

            // Check aspect ratio
            const ratio = img.width / img.height;
            if (ratio > 10 || ratio < 0.1) {
                reject(new Error('Invalid aspect ratio'));
            }

            resolve({ width: img.width, height: img.height });
        };

        img.onerror = () => {
            URL.revokeObjectURL(url);
            reject(new Error('Invalid image file'));
        };

        img.src = url;
    });
}

async uploadImage(file, options = {}) {
    // Validate before uploading
    const dimensions = await this.validateImage(file);
    console.log(`âœ… Image validated: ${dimensions.width}x${dimensions.height}`);

    // Continue with upload...
}
```

---

### 16. **Add Upload Speed Estimation**

**Benefit:** Better UX - show estimated time remaining

**Implementation:**
```javascript
class UploadProgressTracker {
    constructor() {
        this.samples = [];
        this.maxSamples = 10;
    }

    addSample(bytesLoaded, timestamp) {
        this.samples.push({ bytesLoaded, timestamp });

        if (this.samples.length > this.maxSamples) {
            this.samples.shift();
        }
    }

    getUploadSpeed() {
        if (this.samples.length < 2) return 0;

        const first = this.samples[0];
        const last = this.samples[this.samples.length - 1];

        const bytesUploaded = last.bytesLoaded - first.bytesLoaded;
        const timeElapsed = (last.timestamp - first.timestamp) / 1000; // seconds

        return bytesUploaded / timeElapsed; // bytes per second
    }

    getEstimatedTimeRemaining(totalBytes, currentBytes) {
        const speed = this.getUploadSpeed();
        if (speed === 0) return null;

        const remainingBytes = totalBytes - currentBytes;
        return remainingBytes / speed; // seconds
    }

    formatTime(seconds) {
        if (seconds < 60) return `${Math.round(seconds)}s`;
        return `${Math.floor(seconds / 60)}m ${Math.round(seconds % 60)}s`;
    }
}

// Usage in uploadToGCS
const tracker = new UploadProgressTracker();

xhr.upload.addEventListener('progress', (e) => {
    if (e.lengthComputable) {
        tracker.addSample(e.loaded, Date.now());

        const percent = (e.loaded / e.total) * 100;
        const remaining = tracker.getEstimatedTimeRemaining(e.total, e.loaded);
        const speed = tracker.getUploadSpeed() / 1024; // KB/s

        if (onProgress) {
            onProgress({
                percent: percent,
                loaded: e.loaded,
                total: e.total,
                speedKbps: speed,
                remainingTime: remaining
            });
        }

        console.log(`ğŸ“Š Upload: ${Math.round(percent)}% | ${Math.round(speed)} KB/s | ${tracker.formatTime(remaining)} remaining`);
    }
});
```

---

## What's Done Well âœ…

### Strong Points

1. **Clean Separation of Concerns**
   - DirectUploadHandler is self-contained and reusable
   - Clear three-step architecture (signed URL â†’ upload â†’ confirm)
   - Standalone asset file allows use across templates

2. **Excellent Fallback Logic**
   - Graceful degradation to InSPyReNet proxy
   - Maintains user experience even if direct upload fails
   - Transparent to user (no error modals)

3. **Good Progress Tracking**
   - Real-time upload progress via XMLHttpRequest
   - User sees feedback during long uploads
   - Enhances perceived performance

4. **Smart Use of IAM signBlob**
   - Eliminated private key requirement
   - Works with Cloud Run default credentials
   - Simplified deployment (no secrets management)

5. **Proper UUID Usage**
   - Unique upload IDs prevent collisions
   - Timestamp prefixes enable chronological sorting
   - Good path organization (customers/ vs sessions/)

6. **Comprehensive Logging**
   - Clear console messages with emojis for quick scanning
   - Logs include relevant context (file name, size, upload ID)
   - Helps debugging in production

7. **Timeout Protection**
   - 60-second timeout prevents hanging uploads
   - Reasonable for mobile connections
   - Falls back cleanly on timeout

---

## Recommended Actions

### IMMEDIATE (Before Production)

**Priority 1: CRITICAL Security Fixes**
1. Add file type validation (whitelist JPEG/PNG/WEBP only)
2. Add file size limits (50MB max, both frontend + backend)
3. Verify GCS bucket permissions (must NOT be public)
4. Sanitize session_id and customer_id to prevent path traversal
5. Reduce signed URL expiration to 2 minutes

**Priority 2: MAJOR Error Handling**
6. Implement retry logic for direct uploads (3 retries with exponential backoff)
7. Fix confirmation error handling (distinguish fatal vs non-fatal)
8. Add concurrent upload limits (max 2 simultaneous)

### SHORT-TERM (Next Sprint)

**Priority 3: Code Quality**
9. Replace hardcoded API URLs with environment detection
10. Add CSRF protection (tokens or strict CORS)
11. Implement upload metrics logging
12. Add frontend image validation (dimensions, aspect ratio)

### LONG-TERM (Future Enhancement)

**Priority 4: Nice-to-Haves**
13. Implement resumable uploads for better reliability
14. Add upload speed estimation and time remaining
15. Create admin dashboard for upload metrics
16. Implement automatic file cleanup (lifecycle policies)

---

## Testing Checklist

Before deploying to production, verify:

- [ ] **File type validation works**
  - Try uploading .exe file â†’ should reject
  - Try uploading SVG file â†’ should reject
  - Try uploading JPEG/PNG â†’ should accept

- [ ] **File size limits enforced**
  - Try uploading 100MB file â†’ should reject
  - Try uploading 50MB file â†’ should accept (with progress)

- [ ] **Path traversal blocked**
  - Session ID: `../../../admin` â†’ should sanitize to `admin`
  - Session ID: `normal-session-123` â†’ should accept

- [ ] **Bucket permissions secure**
  - Run: `gsutil iam get gs://perkieprints-uploads`
  - Verify: NO `allUsers` or `allAuthenticatedUsers`

- [ ] **Retry logic works**
  - Simulate 503 error â†’ should retry 3x
  - Simulate network timeout â†’ should retry 3x
  - Simulate 404 error â†’ should NOT retry, fail immediately

- [ ] **Fallback works**
  - Kill Gemini API â†’ should fall back to InSPyReNet
  - Verify upload still succeeds (slower but works)

- [ ] **Concurrent uploads limited**
  - Upload 3 pets simultaneously
  - Verify max 2 active at once (check network tab)

- [ ] **CORS protection**
  - Try upload from external domain â†’ should reject (in production)
  - Try upload from Shopify domain â†’ should accept

- [ ] **Error messages helpful**
  - Upload too large â†’ clear error message
  - Invalid file type â†’ clear error message
  - Network error â†’ retry message shown

---

## Code Quality Metrics

| Metric | Score | Target | Status |
|--------|-------|--------|--------|
| **Security** | 4/10 | 9/10 | âŒ CRITICAL issues |
| **Error Handling** | 5/10 | 8/10 | âš ï¸ Needs improvement |
| **Code Organization** | 8/10 | 8/10 | âœ… Good |
| **Documentation** | 7/10 | 8/10 | âœ… Good |
| **Performance** | 7/10 | 9/10 | âš ï¸ Minor issues |
| **Testability** | 6/10 | 8/10 | âš ï¸ Needs work |
| **Maintainability** | 7/10 | 8/10 | âœ… Good |

**Overall Score: 6.1/10**

**After CRITICAL fixes: Estimated 8.5/10**

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FRONTEND (Shopify)                                              â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ DirectUploadHandler                                     â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  1. Get Signed URL  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚   â”‚
â”‚  â”‚     (POST /api/v1/upload/signed-url)      â”‚            â”‚   â”‚
â”‚  â”‚                                            â”‚            â”‚   â”‚
â”‚  â”‚  2. Upload to GCS  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚            â”‚   â”‚
â”‚  â”‚     (PUT signed_url)              â”‚       â”‚            â”‚   â”‚
â”‚  â”‚                                    â”‚       â”‚            â”‚   â”‚
â”‚  â”‚  3. Confirm Upload  â”€â”€â”€â”€â”€â”€â”€â”      â”‚       â”‚            â”‚   â”‚
â”‚  â”‚     (POST /api/v1/upload/  â”‚      â”‚       â”‚            â”‚   â”‚
â”‚  â”‚      confirm) [optional]   â”‚      â”‚       â”‚            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                â”‚      â”‚       â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚      â”‚       â”‚
                                 v      â”‚       v
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ BACKEND (Gemini Artistic API)    â”‚
                    â”‚                                  â”‚
                    â”‚  - Generate signed URLs          â”‚
                    â”‚  - Rate limiting (Firestore)     â”‚
                    â”‚  - Validate requests             â”‚
                    â”‚  - Confirm uploads               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   v (uses IAM signBlob)
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Google Cloud Storage â”‚
                         â”‚                      â”‚
                         â”‚  perkieprints-       â”‚â”€â”€â”€â”€ Direct Upload
                         â”‚  uploads bucket      â”‚     (bypasses API)
                         â”‚                      â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   ^
                                   â”‚
                                   â””â”€â”€ 75% faster than proxy
```

---

## Performance Comparison

| Method | Steps | Total Time | Bottleneck |
|--------|-------|------------|------------|
| **Old (InSPyReNet Proxy)** | Browser â†’ InSPyReNet â†’ GCS | 3.2-13.5s | Cold start + proxy |
| **New (Direct Upload)** | Browser â†’ Gemini API â†’ Browser â†’ GCS | 2.1-6.1s | GCS upload only |
| **Improvement** | Eliminates 2 hops | **54% faster** | âœ… Optimal |

**Breakdown:**
- **Old Method**: Upload (2s) + Cold Start (8s) + Proxy (3s) = 13s
- **New Method**: Signed URL (0.1s) + Upload (2s) = 2.1s
- **Savings**: 10.9s per upload (81% reduction in worst case)

---

## Security Risk Assessment

| Risk | Severity | Likelihood | Impact | Mitigation Priority |
|------|----------|------------|--------|---------------------|
| Arbitrary file upload | CRITICAL | High | Data breach, XSS | P1 - Immediate |
| Storage exhaustion | CRITICAL | Medium | Service disruption, costs | P1 - Immediate |
| Public data exposure | CRITICAL | Low | Privacy violation | P1 - Immediate |
| Path traversal | HIGH | Medium | Data corruption | P1 - Immediate |
| CSRF attacks | HIGH | Medium | Quota abuse | P2 - Short-term |
| URL replay | MEDIUM | Low | Minor quota abuse | P2 - Short-term |

**Risk Score Before Fixes:** 8.5/10 (High Risk)
**Risk Score After Fixes:** 2.5/10 (Low Risk)

---

## Summary

The direct GCS upload implementation is **functionally excellent** with impressive performance gains (75% faster uploads), but has **CRITICAL security vulnerabilities** that must be addressed before production deployment.

### Must Fix Before Production:
1. File type validation (prevent SVG/executable uploads)
2. File size limits (prevent storage abuse)
3. Path sanitization (prevent traversal attacks)
4. Bucket permission verification (prevent data exposure)
5. Signed URL expiration reduction (reduce attack window)

### Should Fix Soon:
6. Retry logic for direct uploads (improve reliability)
7. Better error handling (distinguish fatal errors)
8. CSRF protection (prevent abuse)
9. Environment-based configuration (improve deployment)

### Nice to Have:
10. Upload metrics (improve observability)
11. Resumable uploads (better UX for large files)
12. Image validation (catch errors early)

**Estimated Fix Time:**
- CRITICAL issues (1-5): 4-6 hours
- MAJOR issues (6-9): 3-4 hours
- Total: 1 day to make production-ready

**Post-Fix Code Quality:** 8.5/10 (Excellent)

---

## Files Reviewed

1. `snippets/ks-product-pet-selector-stitch.liquid:1387-1460` - DirectUploadHandler class
2. `snippets/ks-product-pet-selector-stitch.liquid:1888-1953` - uploadToServer function
3. `backend/gemini-artistic-api/src/main.py:308-443` - Signed URL endpoints
4. `assets/direct-upload-handler.js:1-206` - Standalone upload handler
5. `backend/gemini-artistic-api/src/models/schemas.py:69-103` - Request/response schemas

**Total Lines Reviewed:** ~250 lines
**Review Duration:** Comprehensive (45 minutes)
**Next Reviewer:** infrastructure-reliability-engineer (for deployment verification)

---

**Review completed:** 2025-11-09
**Reviewer:** code-quality-reviewer
**Session:** context_session_001
